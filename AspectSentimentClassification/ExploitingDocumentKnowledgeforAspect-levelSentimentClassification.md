- ACL 2018 ShortPaper
- [code]( https://github.com/ruidan/Aspect-level-sentiment.)
- Introduction
    - 已有的大部分方法都是利用LSTM和注意力机制进行建模，LSTM只有在大量数据时
    效果才明显，然而aspect-sentiment的标注数据都很少。但是文档级的标注数据例如亚马逊
    评论是很容易获得的。这些评论里有大量的语言特征和情感标签。
    - 本文假设文档的情感分类可以有助于aspect-level的情感分类。提供了两种迁移策略。
- Model
    - 利用hwt计算注意力，其中h是句子的lstm隐层输出，w是参数，t是评价词的平均词表示
    将注意力得分和lstm文本表示得到加权的文本表示。
    - Transfer:利用普通的LSTM对文档级别的文本进行分类。采用LSTM最后一个隐层向量作为文本表示。
    - Pretrain： 首先进行文档分类。将LSTM，分类层的参数迁移到LSTM+ATT上去finetune
    Aspect情感分类，这里只有Attention的参数是随机初始化的.
    - Multi-task Learning： 同步训练两个任务。二者共享词向量和LSTM的参数，损失函数是J+aU。
    J，U分别是二者的损失函数，a是（0，1）之间的权重，实验设置0.1
    - Combined：首先Pretrain文档分类，然后迁移参数进行finetune MTL
 - Experiments
    - Semeval 2014，2015，2016， 文档数据采用Yelp和Amazon